# -*- coding: utf-8 -*-
"""Muhammad Roshaan Idrees_56177_AI_Lab10

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FOqR1rRs70rp31v24CiNQMxFovtJHinS

**Muhammad Roshaan Idrees**

---


**56177**

# 1: Write a Python program to implement the K-Means algorithm with different dataset and updating different parameters. Also draw the proper graphs to graphically show the output of KNN Algorithm .
"""

from google.colab import files
uploaded = files.upload()

#import libraries
import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import random

# Load the dataset
data = pd.read_csv('clustering.csv')
print("Dataset Shape:", data.shape)
print("\nDataset Info:")
print(data.info())
print("\nFirst 5 rows:")
print(data.head())

# Data preprocessing - handle missing values and select numeric features
data_clean = data.copy()
# Fill missing values with median for numeric columns
numeric_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']
for col in numeric_columns:
    if col in data_clean.columns:
        data_clean[col] = data_clean[col].fillna(data_clean[col].median())

print(f"\nMissing values after cleaning:")
print(data_clean[numeric_columns].isnull().sum())

# Select features for clustering
X = data_clean[["ApplicantIncome", "LoanAmount"]].copy()
print(f"\nSelected features shape: {X.shape}")

# Remove any remaining missing values
X = X.dropna()
print(f"Features shape after removing missing values: {X.shape}")

# Custom K-Means Implementation
class KMeansClustering:
    def __init__(self, k=3, max_iters=100, random_state=42):
        self.k = k
        self.max_iters = max_iters
        self.random_state = random_state
        self.centroids = None
        self.clusters = None
        self.inertia = None

    def initialize_centroids(self, X):
        """Step 1 & 2: Initialize centroids randomly"""
        np.random.seed(self.random_state)
        random_indices = np.random.choice(len(X), self.k, replace=False)
        centroids = X.iloc[random_indices].values
        return centroids

    def euclidean_distance(self, point1, point2):
        """Calculate Euclidean distance between two points"""
        return np.sqrt(np.sum((point1 - point2) ** 2))

    def assign_clusters(self, X, centroids):
        """Step 3: Assign points to nearest centroid"""
        clusters = []
        distances = []

        for i in range(len(X)):
            point = X.iloc[i].values
            dist_to_centroids = [self.euclidean_distance(point, centroid) for centroid in centroids]
            cluster = np.argmin(dist_to_centroids)
            clusters.append(cluster)
            distances.append(min(dist_to_centroids))

        return np.array(clusters), np.array(distances)

    def update_centroids(self, X, clusters):
        """Step 4: Update centroids based on cluster means"""
        new_centroids = []
        for i in range(self.k):
            cluster_points = X[clusters == i]
            if len(cluster_points) > 0:
                new_centroid = cluster_points.mean(axis=0).values
            else:
                # If cluster is empty, reinitialize randomly
                new_centroid = X.sample(1).values[0]
            new_centroids.append(new_centroid)
        return np.array(new_centroids)

    def calculate_inertia(self, distances):
        """Calculate sum of squared distances (inertia)"""
        return np.sum(distances ** 2)

    def fit(self, X):
        """Main K-Means algorithm"""
        # Step 1 & 2: Initialize centroids
        self.centroids = self.initialize_centroids(X)

        print(f"Initial centroids:")
        for i, centroid in enumerate(self.centroids):
            print(f"Cluster {i+1}: ApplicantIncome={centroid[0]:.2f}, LoanAmount={centroid[1]:.2f}")

        # Store history for visualization
        self.centroid_history = [self.centroids.copy()]
        self.cluster_history = []

        # Iterate until convergence or max iterations
        for iteration in range(self.max_iters):
            # Step 3: Assign points to clusters
            clusters, distances = self.assign_clusters(X, self.centroids)
            self.cluster_history.append(clusters.copy())

            # Step 4: Update centroids
            new_centroids = self.update_centroids(X, clusters)
            self.centroid_history.append(new_centroids.copy())

            # Check for convergence
            if np.allclose(self.centroids, new_centroids):
                print(f"Converged after {iteration + 1} iterations")
                break

            self.centroids = new_centroids

            # Calculate inertia
            current_inertia = self.calculate_inertia(distances)
            if iteration % 10 == 0:
                print(f"Iteration {iteration + 1}: Inertia = {current_inertia:.2f}")

        # Final assignment
        self.clusters, final_distances = self.assign_clusters(X, self.centroids)
        self.inertia = self.calculate_inertia(final_distances)

        print(f"\nFinal inertia: {self.inertia:.2f}")
        print("\nFinal centroids:")
        for i, centroid in enumerate(self.centroids):
            print(f"Cluster {i+1}: ApplicantIncome={centroid[0]:.2f}, LoanAmount={centroid[1]:.2f}")

        return self

    def predict(self, X):
        """Predict clusters for new data"""
        clusters, _ = self.assign_clusters(X, self.centroids)
        return clusters

# Visualization functions
def plot_clustering_results(X, kmeans, title="K-Means Clustering Results"):
    """Plot final clustering results"""
    plt.figure(figsize=(15, 5))

    # Plot 1: Final Clusters
    plt.subplot(1, 3, 1)
    colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']

    for i in range(kmeans.k):
        cluster_points = X[kmeans.clusters == i]
        plt.scatter(cluster_points["ApplicantIncome"], cluster_points["LoanAmount"],
                   c=colors[i], label=f'Cluster {i+1}', alpha=0.7, s=50)

    # Plot centroids
    plt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1],
               c='black', marker='X', s=200, label='Centroids', linewidths=2)

    plt.xlabel('Applicant Income')
    plt.ylabel('Loan Amount')
    plt.title(f'{title}\n(K={kmeans.k})')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Plot 2: Initial vs Final Centroids
    plt.subplot(1, 3, 2)
    # Original data
    plt.scatter(X["ApplicantIncome"], X["LoanAmount"], c='lightblue', alpha=0.6, label='Data Points')

    # Initial centroids
    initial_centroids = kmeans.centroid_history[0]
    plt.scatter(initial_centroids[:, 0], initial_centroids[:, 1],
               c='red', marker='o', s=150, label='Initial Centroids', linewidths=2)

    # Final centroids
    plt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1],
               c='black', marker='X', s=200, label='Final Centroids', linewidths=2)

    plt.xlabel('Applicant Income')
    plt.ylabel('Loan Amount')
    plt.title('Centroid Movement')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Plot 3: Cluster Distribution
    plt.subplot(1, 3, 3)
    cluster_counts = [np.sum(kmeans.clusters == i) for i in range(kmeans.k)]
    plt.bar(range(1, kmeans.k + 1), cluster_counts, color=colors[:kmeans.k])
    plt.xlabel('Cluster')
    plt.ylabel('Number of Points')
    plt.title('Cluster Size Distribution')
    plt.grid(True, alpha=0.3)

    for i, count in enumerate(cluster_counts):
        plt.text(i + 1, count + 5, str(count), ha='center', va='bottom')

    plt.tight_layout()
    plt.show()

def plot_iteration_progress(X, kmeans):
    """Plot clustering progress through iterations"""
    n_iterations = min(5, len(kmeans.centroid_history) - 1)  # Show first 5 iterations

    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    axes = axes.flatten()

    colors = ['red', 'blue', 'green', 'orange', 'purple']

    for iter_num in range(n_iterations + 1):
        if iter_num < len(axes):
            ax = axes[iter_num]

            if iter_num < len(kmeans.cluster_history):
                clusters = kmeans.cluster_history[iter_num]
                centroids = kmeans.centroid_history[iter_num]

                for i in range(kmeans.k):
                    cluster_points = X[clusters == i]
                    ax.scatter(cluster_points["ApplicantIncome"], cluster_points["LoanAmount"],
                             c=colors[i], alpha=0.6, s=50)

                ax.scatter(centroids[:, 0], centroids[:, 1],
                         c='black', marker='X', s=150, linewidths=2)

                ax.set_xlabel('Applicant Income')
                ax.set_ylabel('Loan Amount')
                ax.set_title(f'Iteration {iter_num}')
                ax.grid(True, alpha=0.3)

    # Remove empty subplots
    for i in range(n_iterations + 1, len(axes)):
        fig.delaxes(axes[i])

    plt.tight_layout()
    plt.show()

# Analysis with different K values
def analyze_different_k(X, k_values=[2, 3, 4, 5]):
    """Analyze clustering with different K values"""
    inertias = []
    models = []

    plt.figure(figsize=(15, 10))

    for i, k in enumerate(k_values):
        # Train model
        kmeans = KMeansClustering(k=k, random_state=42)
        kmeans.fit(X)
        inertias.append(kmeans.inertia)
        models.append(kmeans)

        # Plot results
        plt.subplot(2, 2, i + 1)
        colors = ['red', 'blue', 'green', 'orange', 'purple', 'brown']

        for cluster_num in range(k):
            cluster_points = X[kmeans.clusters == cluster_num]
            plt.scatter(cluster_points["ApplicantIncome"], cluster_points["LoanAmount"],
                       c=colors[cluster_num], label=f'Cluster {cluster_num+1}', alpha=0.7, s=50)

        plt.scatter(kmeans.centroids[:, 0], kmeans.centroids[:, 1],
                   c='black', marker='X', s=200, label='Centroids', linewidths=2)

        plt.xlabel('Applicant Income')
        plt.ylabel('Loan Amount')
        plt.title(f'K={k} (Inertia: {kmeans.inertia:.2f})')
        plt.legend()
        plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    # Elbow curve
    plt.figure(figsize=(10, 6))
    plt.plot(k_values, inertias, 'bo-', linewidth=2, markersize=8)
    plt.xlabel('Number of Clusters (K)')
    plt.ylabel('Inertia (Sum of Squared Distances)')
    plt.title('Elbow Method for Optimal K')
    plt.grid(True, alpha=0.3)

    for k, inertia in zip(k_values, inertias):
        plt.text(k, inertia + 1000, f'{inertia:.0f}', ha='center', va='bottom')

    plt.show()

    return models, inertias

# Main execution
print("=" * 80)
print("K-MEANS CLUSTERING IMPLEMENTATION FROM SCRATCH")
print("=" * 80)

# Test with different parameters
print("\n1. CLUSTERING WITH K=3")
print("-" * 40)
kmeans3 = KMeansClustering(k=3, random_state=42)
kmeans3.fit(X)
plot_clustering_results(X, kmeans3, "K-Means Clustering (K=3)")

print("\n2. CLUSTERING ITERATION PROGRESS")
print("-" * 40)
plot_iteration_progress(X, kmeans3)

print("\n3. ANALYSIS WITH DIFFERENT K VALUES")
print("-" * 40)
models, inertias = analyze_different_k(X, k_values=[2, 3, 4, 5])

print("\n4. CLUSTER STATISTICS")
print("-" * 40)
for i, model in enumerate(models):
    k = [2, 3, 4, 5][i]
    print(f"\nK={k}:")
    print(f"Inertia: {model.inertia:.2f}")

    for cluster_num in range(k):
        cluster_points = X[model.clusters == cluster_num]
        print(f"  Cluster {cluster_num + 1}:")
        print(f"    Size: {len(cluster_points)} points")
        print(f"    Avg Income: {cluster_points['ApplicantIncome'].mean():.2f}")
        print(f"    Avg Loan Amount: {cluster_points['LoanAmount'].mean():.2f}")

# Additional analysis with different features
print("\n" + "=" * 80)
print("ADDITIONAL ANALYSIS WITH DIFFERENT FEATURE COMBINATIONS")
print("=" * 80)

# Try different feature combinations
feature_combinations = [
    ("ApplicantIncome", "LoanAmount"),
    ("ApplicantIncome", "CoapplicantIncome"),
    ("LoanAmount", "Credit_History")
]

for i, (feat1, feat2) in enumerate(feature_combinations):
    if feat1 in X.columns and feat2 in X.columns:
        print(f"\nAnalysis with features: {feat1} vs {feat2}")
        print("-" * 40)

        X_features = data_clean[[feat1, feat2]].dropna()
        kmeans_features = KMeansClustering(k=3, random_state=42)
        kmeans_features.fit(X_features)

        plt.figure(figsize=(12, 5))

        # Plot clustering results
        plt.subplot(1, 2, 1)
        colors = ['red', 'blue', 'green']

        for cluster_num in range(3):
            cluster_points = X_features[kmeans_features.clusters == cluster_num]
            plt.scatter(cluster_points[feat1], cluster_points[feat2],
                       c=colors[cluster_num], label=f'Cluster {cluster_num+1}', alpha=0.7, s=50)

        plt.scatter(kmeans_features.centroids[:, 0], kmeans_features.centroids[:, 1],
                   c='black', marker='X', s=200, label='Centroids', linewidths=2)

        plt.xlabel(feat1)
        plt.ylabel(feat2)
        plt.title(f'Clustering: {feat1} vs {feat2}')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # Plot cluster sizes
        plt.subplot(1, 2, 2)
        cluster_counts = [np.sum(kmeans_features.clusters == i) for i in range(3)]
        plt.bar(range(1, 4), cluster_counts, color=colors)
        plt.xlabel('Cluster')
        plt.ylabel('Number of Points')
        plt.title('Cluster Size Distribution')
        plt.grid(True, alpha=0.3)

        for i, count in enumerate(cluster_counts):
            plt.text(i + 1, count + 2, str(count), ha='center', va='bottom')

        plt.tight_layout()
        plt.show()

print("\n" + "=" * 80)
print("K-MEANS CLUSTERING IMPLEMENTATION COMPLETED SUCCESSFULLY!")
print("=" * 80)